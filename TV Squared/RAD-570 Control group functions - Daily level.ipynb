{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBh_uUiPKang"
   },
   "source": [
    "## Pipeline \n",
    "\n",
    "Main goal. Pipeline skeleton to:\n",
    "1. Classify households according to some grouping\n",
    "2. Compute TV metrics\n",
    "3. Testing sample size methodologies\n",
    "\n",
    "\n",
    "Pipeline structure\n",
    "1. Send relevant info to filter crosswalk-eventlog data (client, week for crosswalk, campaign dates, etc)\n",
    "2. Creating base data frame with ctrl group and visited flags\n",
    "3. Calculate metrics and choose variables to group data set\n",
    "4. Sample sizes analysis (100 samples of total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JWrv-aBKani"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "currentdir = os.getcwd()\n",
    "correctdir = currentdir.rsplit('tv2ds/',1)[0]\n",
    "os.chdir(correctdir)\n",
    "\n",
    "from tv2ds.ds_lib import notebook_prodrun\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "from datetime import datetime, timedelta\n",
    "import tvsquared.settings\n",
    "from tvsquared.lib.request import Request\n",
    "from tvsquared.lib.athena import AthenaDatabase\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIUEkKLjKanj",
    "outputId": "29b6fd7f-5078-4007-efd3-492f48ca4284"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'produsa'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_prodrun.set_env('US', prodrunenv='PROD')\n",
    "crosswalk_suffix = os.environ.get('TV2PRODRUNENV').lower()\n",
    "crosswalk_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jl8J2FB3Kank"
   },
   "outputs": [],
   "source": [
    "def make_request(clientid, brandid = 1, datefrom=False, dateto=False):\n",
    "    # Helper Function to make a request from client, brand, and date range arguments\n",
    "    # Returns the request object\n",
    "    if datefrom and dateto:\n",
    "        request = Request(clientarg=False, brandarg=False, datesarg=False)\n",
    "        datefrom = datetime.datetime.strptime(datefrom, '%Y-%m-%d')\n",
    "        dateto = datetime.datetime.strptime(dateto, '%Y-%m-%d')\n",
    "        request = request.init(partnerid=None, clientid=clientid, brandid=brandid,datefrom=datefrom, dateto=dateto,loglevel=-1, extargs=None, request=None, usespark=None, readPreference=None,prodrun=False)\n",
    "        return(request)\n",
    "    else:\n",
    "        request = Request(clientarg=False, brandarg=False, datesarg=False)\n",
    "        request = request.init(partnerid=None, clientid=clientid, brandid=brandid,datefrom=None, dateto=None,loglevel=-1, extargs=None, request=None, usespark=None, readPreference=None,prodrun=False)\n",
    "        return(request)\n",
    "\n",
    "\n",
    "def query_athena(request, query, copy_to_local=False):\n",
    "    athena_db = AthenaDatabase.get_client_database(request)\n",
    "    query_results = AthenaDatabase.execute_query(athena_db, query, copy_to_local=copy_to_local)\n",
    "    df = pd.DataFrame(query_results)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QburZjWKanl"
   },
   "outputs": [],
   "source": [
    "client = {'clientid': 9306}\n",
    "request = make_request(client['clientid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOHXhWB1Kanl"
   },
   "source": [
    "## ✅️ Step1. Send relevant info to filter crosswalk-eventlog data\n",
    "\n",
    "### ➡️ Client and information used to extract sample data:\n",
    "**Drizly**<br>\n",
    "vendor_name='inscape', yy='2022', mm='03',dd='28',crosswalk_suffix='produsa',dateto='2022-03-31', datefrom='2022-03-01', clientid='c9306_drizly'<br>\n",
    "\n",
    "**Therealreal**<br>\n",
    "vendor_name='inscape', yy='2022', mm='01',dd='24',crosswalk_suffix='produsa',dateto='2022-01-30', datefrom='2022-01-01', clientid='c9534_uti'<br>\n",
    "\n",
    "**Uti**<br>\n",
    "vendor_name='inscape', yy='2022', mm='01',dd='24',crosswalk_suffix='produsa',dateto='2022-01-30', datefrom='2022-01-01', clientid='9534'<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdHN2Ln0Kanm"
   },
   "outputs": [],
   "source": [
    "# Inputs needed for queries in Athena\n",
    "\n",
    "yy_input='2022' \n",
    "mm_input='03'\n",
    "dd_input='28'\n",
    "dateto_input='2022-04-03' \n",
    "# dateto_input='2022-03-31' \n",
    "datefrom_input='2022-03-01'  \n",
    "lookback_window_input=30\n",
    "clientid_input='c9306_drizly'\n",
    "# clientid_input='c9534_uti'\n",
    "# clientid_input='c16319_the_realreal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGkz7E9FKanm"
   },
   "source": [
    "### ➡️ Control data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUP9Y9AqKanm"
   },
   "source": [
    "#### ➜ All control hhs per day/ per week - my function\n",
    "\n",
    "Tables created: \n",
    "-  df_control_pday\n",
    "- control_n_total\n",
    "\n",
    "This query is bring back: 8,040,334 unique hhs ids as expected but only 106,355 are catalogued in the eventlog with an event, so only those will have a date attached to it.<br/>\n",
    "The rest, which is the mayority (7m), have no date attached to it and they are just valid and active .. so how to turn this into daily control groups? is there a date variable that can be used in the campaign universe? <br/>\n",
    "\n",
    "**note 6th October**: <br/>\n",
    "I am still working on this section, it is not a straight forward task. it is under investigation in RAD-570 Original query exploration. \n",
    "I am using a function that Michael shared with me.<br/>\n",
    "\n",
    "**note 11th October**:<br/>\n",
    "I ran and modified the function Michael shared with me and I do now have control groups at daily and weekly levels. However, for the control exposed, I modified the function I had at campaign level to add just a date variable as new information and keeping in mind the high level figures I already had should still add up (I reckoned, it was just a matter of adding new infromation, but the totals should be the same). The thing now is that these numbers are very different from the visitied in Michael's function so now sure this if this is right anymore. \n",
    "Maybe I need to run Michael's function for the exposed group and see how those numbers compare to the ones I have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHCA8qKFKann"
   },
   "outputs": [],
   "source": [
    "def query_control_perday(subquery_name: str, yy_value:str, mm_value:str, dd_value:str, dateto_value:str, datefrom_value:str, clientid_value:str): \n",
    "   return '''\n",
    "   with filtered_hh as (\n",
    "      select \n",
    "         key_value as mapped_tv2_hhid\n",
    "      from {crosswalk_suffix}_modeldata.crosswalk\n",
    "      where \n",
    "         yy='{yy}' \n",
    "         and mm='{mm}' \n",
    "         and dd='{dd}'\n",
    "         and key_name ='tv2_hhid' \n",
    "         and vendor_name = '{vendor_name}'\n",
    "         and excluded_stamp is null\n",
    "      ),\n",
    "      campaign_universe as (\n",
    "         select \n",
    "            complex_ranges.mapped_tv2_hhid \n",
    "         FROM {crosswalk_suffix}_modeldata.crosswalk cw\n",
    "         CROSS JOIN UNNEST(complex_range) AS t (complex_ranges)\n",
    "         join filtered_hh fh on fh.mapped_tv2_hhid = complex_ranges.mapped_tv2_hhid\n",
    "         where \n",
    "            vendor_name = '{vendor_name}'\n",
    "            and complex_ranges.first_seen <= timestamp '{dateto}' + interval '1' day\n",
    "            and complex_ranges.last_seen >= timestamp '{datefrom}' \n",
    "            and key_name = 'tv2_hhid'\n",
    "            and yy='{yy}'\n",
    "            and mm='{mm}' \n",
    "            and dd='{dd}'\n",
    "      ),\n",
    "      client_eventlog as (\n",
    "         select \n",
    "            date_trunc('day', datadatetime) as day,\n",
    "            crosswalk_link_id,\n",
    "            event_class,\n",
    "            in_scope,\n",
    "            datadatetime\n",
    "         from {clientid}_{crosswalk_suffix}.eventlog\n",
    "         where \n",
    "            datadatetime between timestamp '{datefrom}' \n",
    "            and timestamp '{dateto}' + interval '7' day\n",
    "      ),\n",
    "      hh_impressed_30days as (\n",
    "         select\n",
    "            distinct crosswalk_link_id as mapped_tv2_hhid\n",
    "         from campaign_universe ex\n",
    "         join client_eventlog ev on ev.crosswalk_link_id = ex.mapped_tv2_hhid\n",
    "         where\n",
    "            event_class='impression'\n",
    "            and datadatetime between timestamp '{datefrom}' - interval '30' day    \n",
    "            and timestamp '{dateto}' + interval '1' day + interval '6' day\n",
    "            and in_scope\n",
    "      ),\n",
    "      hh_control as (\n",
    "         select\n",
    "            distinct cu.mapped_tv2_hhid\n",
    "         from campaign_universe cu\n",
    "         left join hh_impressed_30days hh on hh.mapped_tv2_hhid  = cu.mapped_tv2_hhid\n",
    "         where hh.mapped_tv2_hhid is null\n",
    "      ),\n",
    "      hh_control_perday as (\n",
    "         select\n",
    "            day,\n",
    "            mapped_tv2_hhid\n",
    "         from hh_control\n",
    "         left join client_eventlog on crosswalk_link_id = mapped_tv2_hhid\n",
    "      )\n",
    "      select\n",
    "         *\n",
    "      from {result}\n",
    "\n",
    "\n",
    "'''.format(\n",
    "      vendor_name='inscape', \n",
    "      yy=yy_value, mm=mm_value,dd=dd_value,\n",
    "      crosswalk_suffix='produsa',\n",
    "      dateto=dateto_value, \n",
    "      datefrom=datefrom_value,  \n",
    "      clientid=clientid_value,\n",
    "      result=subquery_name\n",
    "      )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-G_RIztKann"
   },
   "outputs": [],
   "source": [
    "df_control_pday= query_athena(\n",
    "    request, \n",
    "    query_control_perday(\n",
    "        subquery_name='hh_control_perday',\n",
    "        yy_value=yy_input, mm_value=mm_input,dd_value=dd_input,\n",
    "        dateto_value=dateto_input, \n",
    "        datefrom_value=datefrom_input,  \n",
    "        clientid_value=clientid_input,\n",
    "        ))#.astype({\"ctrl_hhs\": \"int\"}) #--> need to us this for the previous code when I tried bringing flags directly from Athena, this was the problem\n",
    "\n",
    "df_control_pday.day = pd.to_datetime(df_control_pday.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VebepTz8Kann",
    "outputId": "83d57cab-e232-4cb7-be35-33deebe3a52d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8228310, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control_pday.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tMerOetKano"
   },
   "outputs": [],
   "source": [
    "df_control_pday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxOG_pc3Kano",
    "outputId": "edffc78c-9120-4485-b18f-b9f1ade94a85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8040334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_control_pday.ctrl_hhs.sum()\n",
    "df_control_pday.mapped_tv2_hhid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjMbRY24Kano",
    "outputId": "10f51a81-2cb4-4f5f-a364-c5807c2b8826"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>2902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-02</th>\n",
       "      <td>2837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03</th>\n",
       "      <td>2971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-04</th>\n",
       "      <td>3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-05</th>\n",
       "      <td>3518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-06</th>\n",
       "      <td>3117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>2764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>2782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-10</th>\n",
       "      <td>2743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-11</th>\n",
       "      <td>3084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-12</th>\n",
       "      <td>3119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-13</th>\n",
       "      <td>2639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "      <td>2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-16</th>\n",
       "      <td>3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-17</th>\n",
       "      <td>3544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-18</th>\n",
       "      <td>3752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-19</th>\n",
       "      <td>3895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-20</th>\n",
       "      <td>3054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-21</th>\n",
       "      <td>2141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-22</th>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-23</th>\n",
       "      <td>2326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-24</th>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-25</th>\n",
       "      <td>3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-26</th>\n",
       "      <td>3395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-27</th>\n",
       "      <td>2672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-28</th>\n",
       "      <td>2424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29</th>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-30</th>\n",
       "      <td>3172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>3248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-02</th>\n",
       "      <td>3437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>2984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>2598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-05</th>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06</th>\n",
       "      <td>2890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>7975585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            n_total\n",
       "day                \n",
       "2022-03-01     2902\n",
       "2022-03-02     2837\n",
       "2022-03-03     2971\n",
       "2022-03-04     3292\n",
       "2022-03-05     3518\n",
       "2022-03-06     3117\n",
       "2022-03-07     1756\n",
       "2022-03-08     2764\n",
       "2022-03-09     2782\n",
       "2022-03-10     2743\n",
       "2022-03-11     3084\n",
       "2022-03-12     3119\n",
       "2022-03-13     2639\n",
       "2022-03-14     2099\n",
       "2022-03-15     2111\n",
       "2022-03-16     3147\n",
       "2022-03-17     3544\n",
       "2022-03-18     3752\n",
       "2022-03-19     3895\n",
       "2022-03-20     3054\n",
       "2022-03-21     2141\n",
       "2022-03-22     2063\n",
       "2022-03-23     2326\n",
       "2022-03-24     2777\n",
       "2022-03-25     3177\n",
       "2022-03-26     3395\n",
       "2022-03-27     2672\n",
       "2022-03-28     2424\n",
       "2022-03-29     2566\n",
       "2022-03-30     3172\n",
       "2022-03-31     3364\n",
       "2022-04-01     3248\n",
       "2022-04-02     3437\n",
       "2022-04-03     2984\n",
       "2022-04-04     2598\n",
       "2022-04-05     1995\n",
       "2022-04-06     2890\n",
       "NaT         7975585"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_n_total = df_control_pday.groupby(['day'], dropna=False).agg(n_total=(\"mapped_tv2_hhid\", \"nunique\")) #, dropna=False\n",
    "control_n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnrXZsvRKano",
    "outputId": "1bfec1ec-1345-40a6-bca5-0a9194f527a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8081940"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_n_total.n_total.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5zh14ekKanp"
   },
   "source": [
    "#### ➜ All control hhs per day/ per week - Michael function\n",
    "tables created: \n",
    "- df_control_daily\n",
    "- df_control_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4d_Uj-PKanp"
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"lala\": [\"1.0\", \"2.3\"]}).assign(lala=lambda df: np.floor(pd.to_numeric(df.lala, errors=\"coerce\")).astype(\"Int64\"))\n",
    "request_ctrl_fun = make_request(9306,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "invNMLrgKanp"
   },
   "outputs": [],
   "source": [
    "def get_control_group(\n",
    "    request, datefrom_value:str, dateto_value:str, yy_value:str, mm_value:str, dd_value:str,clientid_value:str, \n",
    "    granularity:str, lookback_window:int, filter_linear=True,):\n",
    "    \"\"\"\n",
    "    Slow version to get us off the ground. Take a date range and then it will run the athena query per granularity\n",
    "    specified to get the aggregate totals for eligible control households and the number of visits\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    request : Request\n",
    "        request object\n",
    "    datefrom : str\n",
    "        start date for date range\n",
    "    dateto : str\n",
    "        end date for date range\n",
    "    cw_yy : int\n",
    "        crosswalk year\n",
    "    cw_mm : int\n",
    "        crosswalk month\n",
    "    cw_dd : int\n",
    "        crosswalk day\n",
    "    granularity: what frequency to pass to pandas for date range, W (weekly) or D (daily) -- (hint: weekly on Monday is 'W-MON' ?)\n",
    "    lookback_window : int\n",
    "        how far to look back to fund elibigle households, e.g. not exposed in last '30' days\n",
    "    crosswalk_suffix : str\n",
    "        which env are you using, default 'prod'\n",
    "    vendor_name : str\n",
    "        crosswalk vendor name e.g. inscape\n",
    "    filter_linear : bool\n",
    "        should we consider both OTT and Linear impressions when building the control group? default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        control households and visits per granularity specified, with visit rate calculated\n",
    "\n",
    "    Version control\n",
    "    -------\n",
    "    Created by: Michael Comerford\n",
    "    Last Modified by: Chio Martinez 10th Oct \n",
    "        - introduced change on concatenated df to use concat instead of append in the final df\n",
    "        - introduced granularity functionality: 'W' and 'D'\n",
    "        - changes to function call and parameters \n",
    "\n",
    "    \"\"\"\n",
    "    # get db from request object\n",
    "    athena_db = AthenaDatabase.get_client_database(request)\n",
    "\n",
    "    # create list of dates from specified range\n",
    "    datelist = pd.date_range(start=datefrom_input, end=dateto_input, freq=granularity).to_list()\n",
    "\n",
    "    # if filter_linear is true we need to remove the event filter\n",
    "    overlap = ''\n",
    "    if not filter_linear:\n",
    "        overlap = \"and event = 'vod'\"\n",
    "\n",
    "    # we'll store the aggregated results in a DataFrame\n",
    "    dfs=[]\n",
    "\n",
    "\n",
    "    for date in datelist:\n",
    "\n",
    "        # if granularity = 'W' then date datefrom=date - 7 days, \n",
    "        datefrom_granularity = date\n",
    "        if granularity == 'W':\n",
    "            datefrom_granularity = date - timedelta(days=6)\n",
    "\n",
    "        print(\n",
    "            '''Getting Data for dates between {datefrom} until {dateto}...'''\n",
    "            .format(\n",
    "                dateto=date, \n",
    "                datefrom=datefrom_granularity)\n",
    "            )\n",
    "\n",
    "        query = \"\"\"\n",
    "        -- select universe of unfiltered people for time range\n",
    "        \n",
    "\n",
    "        with filtered_hh as (\n",
    "        select \n",
    "            key_value as mapped_tv2_hhid\n",
    "        from {crosswalk_suffix}_modeldata.crosswalk\n",
    "        where \n",
    "            yy='{yy}' \n",
    "            and mm='{mm}' \n",
    "            and dd='{dd}'\n",
    "            and key_name ='tv2_hhid' \n",
    "            and vendor_name = '{vendor_name}'\n",
    "            and excluded_stamp is null\n",
    "        ),\n",
    "        campaign_universe as (\n",
    "            select \n",
    "                complex_ranges.mapped_tv2_hhid \n",
    "            FROM {crosswalk_suffix}_modeldata.crosswalk cw\n",
    "            CROSS JOIN UNNEST(complex_range) AS t (complex_ranges)\n",
    "            join filtered_hh fh on fh.mapped_tv2_hhid = complex_ranges.mapped_tv2_hhid\n",
    "            where \n",
    "                vendor_name = '{vendor_name}'\n",
    "                and complex_ranges.first_seen <= timestamp '{dateto}' + interval '1' day\n",
    "                and complex_ranges.last_seen >= timestamp '{datefrom}' \n",
    "                and key_name = 'tv2_hhid'\n",
    "                and yy='{yy}'\n",
    "                and mm='{mm}' \n",
    "                and dd='{dd}'\n",
    "        ),\n",
    "        client_eventlog as (\n",
    "            select \n",
    "            *\n",
    "            from {clientid}_{crosswalk_suffix}.eventlog\n",
    "            where \n",
    "                datadatetime between timestamp '{datefrom}' \n",
    "                and timestamp '{dateto}' + interval '7' day\n",
    "        ),\n",
    "        hh_impressed_30days as (\n",
    "            select\n",
    "                distinct crosswalk_link_id as mapped_tv2_hhid\n",
    "            from campaign_universe ex\n",
    "            join client_eventlog ev on ev.crosswalk_link_id = ex.mapped_tv2_hhid\n",
    "            where\n",
    "                event_class='impression'\n",
    "                {overlap}\n",
    "                and datadatetime between timestamp '{datefrom}' - interval '{lookback_window}' day    \n",
    "                and timestamp '{dateto}' + interval '7' day\n",
    "                and in_scope\n",
    "        ),\n",
    "        hh_control as (\n",
    "            select\n",
    "                distinct cu.mapped_tv2_hhid\n",
    "            from campaign_universe cu\n",
    "            left join hh_impressed_30days hh on hh.mapped_tv2_hhid  = cu.mapped_tv2_hhid\n",
    "            where hh.mapped_tv2_hhid is null\n",
    "        ),\n",
    "        n_hh_control_visited as (\n",
    "            select \n",
    "                count(distinct mapped_tv2_hhid) as ctrl_visited\n",
    "            from client_eventlog\n",
    "            join hh_control on crosswalk_link_id = mapped_tv2_hhid\n",
    "            where\n",
    "                event_class ='response' and event= 'all response'\n",
    "                and datadatetime between timestamp '{datefrom}' \n",
    "                and timestamp '{dateto}' + interval '7' day\n",
    "                and in_scope in (TRUE, null)\n",
    "        ),\n",
    "        n_hh_control as (\n",
    "            select CAST(count(distinct mapped_tv2_hhid) AS double) as ctrl_hh\n",
    "            from hh_control\n",
    "        ),\n",
    "        final_results as (\n",
    "            select *\n",
    "            from n_hh_control_visited\n",
    "            cross join n_hh_control\n",
    "        )\n",
    "        select\n",
    "            '{datefrom}' as day, \n",
    "            ctrl_hh,\n",
    "            ctrl_visited,\n",
    "            ctrl_visited/ctrl_hh as ctrl_vr\n",
    "        from final_results\n",
    "\n",
    "        \"\"\".format(\n",
    "            yy=yy_value, mm=mm_value, dd=dd_value,\n",
    "            dateto=date, \n",
    "            datefrom=datefrom_granularity,  \n",
    "            clientid=clientid_value,\n",
    "            lookback_window=lookback_window, \n",
    "            overlap=overlap,\n",
    "            vendor_name='inscape',\n",
    "            crosswalk_suffix='produsa',\n",
    "            )   \n",
    "\n",
    "        query_results = AthenaDatabase.execute_query(athena_db, query)\n",
    "        \n",
    "        dfs.append(pd.DataFrame(query_results))\n",
    "        results = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "        request.log.info(query)\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSAP8hIhKanq",
    "outputId": "f2b33095-14e4-46d4-de02-ea1b97bab27f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data for dates between 2022-03-01 00:00:00 until 2022-03-01 00:00:00...\n",
      "Getting Data for dates between 2022-03-02 00:00:00 until 2022-03-02 00:00:00...\n",
      "Getting Data for dates between 2022-03-03 00:00:00 until 2022-03-03 00:00:00...\n",
      "Getting Data for dates between 2022-03-04 00:00:00 until 2022-03-04 00:00:00...\n",
      "Getting Data for dates between 2022-03-05 00:00:00 until 2022-03-05 00:00:00...\n",
      "Getting Data for dates between 2022-03-06 00:00:00 until 2022-03-06 00:00:00...\n",
      "Getting Data for dates between 2022-03-07 00:00:00 until 2022-03-07 00:00:00...\n",
      "Getting Data for dates between 2022-03-08 00:00:00 until 2022-03-08 00:00:00...\n",
      "Getting Data for dates between 2022-03-09 00:00:00 until 2022-03-09 00:00:00...\n",
      "Getting Data for dates between 2022-03-10 00:00:00 until 2022-03-10 00:00:00...\n",
      "Getting Data for dates between 2022-03-11 00:00:00 until 2022-03-11 00:00:00...\n",
      "Getting Data for dates between 2022-03-12 00:00:00 until 2022-03-12 00:00:00...\n",
      "Getting Data for dates between 2022-03-13 00:00:00 until 2022-03-13 00:00:00...\n",
      "Getting Data for dates between 2022-03-14 00:00:00 until 2022-03-14 00:00:00...\n",
      "Getting Data for dates between 2022-03-15 00:00:00 until 2022-03-15 00:00:00...\n",
      "Getting Data for dates between 2022-03-16 00:00:00 until 2022-03-16 00:00:00...\n",
      "Getting Data for dates between 2022-03-17 00:00:00 until 2022-03-17 00:00:00...\n",
      "Getting Data for dates between 2022-03-18 00:00:00 until 2022-03-18 00:00:00...\n",
      "Getting Data for dates between 2022-03-19 00:00:00 until 2022-03-19 00:00:00...\n",
      "Getting Data for dates between 2022-03-20 00:00:00 until 2022-03-20 00:00:00...\n",
      "Getting Data for dates between 2022-03-21 00:00:00 until 2022-03-21 00:00:00...\n",
      "Getting Data for dates between 2022-03-22 00:00:00 until 2022-03-22 00:00:00...\n",
      "Getting Data for dates between 2022-03-23 00:00:00 until 2022-03-23 00:00:00...\n",
      "Getting Data for dates between 2022-03-24 00:00:00 until 2022-03-24 00:00:00...\n",
      "Getting Data for dates between 2022-03-25 00:00:00 until 2022-03-25 00:00:00...\n",
      "Getting Data for dates between 2022-03-26 00:00:00 until 2022-03-26 00:00:00...\n",
      "Getting Data for dates between 2022-03-27 00:00:00 until 2022-03-27 00:00:00...\n",
      "Getting Data for dates between 2022-03-28 00:00:00 until 2022-03-28 00:00:00...\n",
      "Getting Data for dates between 2022-03-29 00:00:00 until 2022-03-29 00:00:00...\n",
      "Getting Data for dates between 2022-03-30 00:00:00 until 2022-03-30 00:00:00...\n",
      "Getting Data for dates between 2022-03-31 00:00:00 until 2022-03-31 00:00:00...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "day             datetime64[ns]\n",
       "ctrl_hh                  Int64\n",
       "ctrl_visited             Int64\n",
       "ctrl_vr                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "granularity_input='D'\n",
    "\n",
    "def to_int(col: pd.Series):\n",
    "    return np.floor(pd.to_numeric(col, errors=\"coerce\")).astype(\"Int64\")\n",
    "\n",
    "\n",
    "df_control_daily= get_control_group(\n",
    "    request=request_ctrl_fun, \n",
    "    yy_value=yy_input, mm_value=mm_input,dd_value=dd_input,\n",
    "    granularity=granularity_input,\n",
    "    lookback_window=lookback_window_input,\n",
    "    dateto_value=dateto_input, \n",
    "    datefrom_value=datefrom_input,  \n",
    "    clientid_value=clientid_input,\n",
    "    ).assign(\n",
    "        ctrl_hh=lambda df: to_int(df.ctrl_hh),\n",
    "        ctrl_visited=lambda df: to_int(df.ctrl_visited),\n",
    "    )\n",
    "\n",
    "df_control_daily.day = pd.to_datetime(df_control_daily.day)\n",
    "df_control_daily.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvUr-mEVKanq",
    "outputId": "9a24d168-4de8-4e69-bc3c-0212d964ab26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>ctrl_hh</th>\n",
       "      <th>ctrl_visited</th>\n",
       "      <th>ctrl_vr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>8637847</td>\n",
       "      <td>17999</td>\n",
       "      <td>0.0020837368385895234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>8651376</td>\n",
       "      <td>18100</td>\n",
       "      <td>0.0020921527396335566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>8651396</td>\n",
       "      <td>18248</td>\n",
       "      <td>0.0021092549687934756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>8629766</td>\n",
       "      <td>18041</td>\n",
       "      <td>0.002090554946681057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-05</td>\n",
       "      <td>8593316</td>\n",
       "      <td>17899</td>\n",
       "      <td>0.0020828979174046434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         day  ctrl_hh  ctrl_visited                ctrl_vr\n",
       "0 2022-03-01  8637847         17999  0.0020837368385895234\n",
       "1 2022-03-02  8651376         18100  0.0020921527396335566\n",
       "2 2022-03-03  8651396         18248  0.0021092549687934756\n",
       "3 2022-03-04  8629766         18041   0.002090554946681057\n",
       "4 2022-03-05  8593316         17899  0.0020828979174046434"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PKt4mW_Kanq",
    "outputId": "5c08cfba-fb35-44ab-845e-3bb1ca49acb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data for dates between 2022-02-28 00:00:00 until 2022-03-06 00:00:00...\n",
      "Getting Data for dates between 2022-03-07 00:00:00 until 2022-03-13 00:00:00...\n",
      "Getting Data for dates between 2022-03-14 00:00:00 until 2022-03-20 00:00:00...\n",
      "Getting Data for dates between 2022-03-21 00:00:00 until 2022-03-27 00:00:00...\n",
      "Getting Data for dates between 2022-03-28 00:00:00 until 2022-04-03 00:00:00...\n"
     ]
    }
   ],
   "source": [
    "granularity_input='W'\n",
    "\n",
    "df_control_weekly= get_control_group(\n",
    "    request=request_ctrl_fun, \n",
    "    yy_value=yy_input, mm_value=mm_input,dd_value=dd_input,\n",
    "    granularity=granularity_input,\n",
    "    lookback_window=lookback_window_input,\n",
    "    dateto_value=dateto_input, \n",
    "    datefrom_value=datefrom_input,  \n",
    "    clientid_value=clientid_input,\n",
    "    )\n",
    "\n",
    "df_control_weekly.day = pd.to_datetime(df_control_weekly.day).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3auW53QKanq",
    "outputId": "55e0d95a-6383-47de-8537-346937980b27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>ctrl_hh</th>\n",
       "      <th>ctrl_visited</th>\n",
       "      <th>ctrl_vr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>8389057.0</td>\n",
       "      <td>28908</td>\n",
       "      <td>0.0034459176996890113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>8324378.0</td>\n",
       "      <td>29325</td>\n",
       "      <td>0.0035227857264530757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-14</td>\n",
       "      <td>8262491.0</td>\n",
       "      <td>29041</td>\n",
       "      <td>0.0035147995925199796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>8297656.0</td>\n",
       "      <td>28593</td>\n",
       "      <td>0.0034459129180578227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>8308905.0</td>\n",
       "      <td>28947</td>\n",
       "      <td>0.0034838525654102438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          day    ctrl_hh ctrl_visited                ctrl_vr\n",
       "0  2022-02-28  8389057.0        28908  0.0034459176996890113\n",
       "1  2022-03-07  8324378.0        29325  0.0035227857264530757\n",
       "2  2022-03-14  8262491.0        29041  0.0035147995925199796\n",
       "3  2022-03-21  8297656.0        28593  0.0034459129180578227\n",
       "4  2022-03-28  8308905.0        28947  0.0034838525654102438"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control_weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI5mM4VfKanr"
   },
   "source": [
    "#### ➜ Control visited per day\n",
    "\n",
    "Tables created: \n",
    "- df_control_visited_pday\n",
    "- df_control_visited_pday_agg\n",
    "\n",
    "**note 11th Oct:** <br/>\n",
    "The function above creates the visited per day as well, but I created this to follow on the same logic as I did at campaign level and just adding date as new information. The thing now is that these numbers are very different from the visitied in the function above so now sure this if this is right anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYNb_R9lKanr"
   },
   "outputs": [],
   "source": [
    "def query_control_visited_perday(subquery_name: str, yy_value:str, mm_value:str, dd_value:str, dateto_value:str, datefrom_value:str, clientid_value:str): \n",
    "   return '''\n",
    "   with filtered_hh as (\n",
    "      select \n",
    "         key_value as mapped_tv2_hhid\n",
    "      from {crosswalk_suffix}_modeldata.crosswalk\n",
    "      where \n",
    "         yy='{yy}' \n",
    "         and mm='{mm}' \n",
    "         and dd='{dd}'\n",
    "         and key_name ='tv2_hhid' \n",
    "         and vendor_name = '{vendor_name}'\n",
    "         and excluded_stamp is null\n",
    "      ),\n",
    "      campaign_universe as (\n",
    "         select \n",
    "            complex_ranges.mapped_tv2_hhid \n",
    "         FROM {crosswalk_suffix}_modeldata.crosswalk cw\n",
    "         CROSS JOIN UNNEST(complex_range) AS t (complex_ranges)\n",
    "         join filtered_hh fh on fh.mapped_tv2_hhid = complex_ranges.mapped_tv2_hhid\n",
    "         where \n",
    "            vendor_name = '{vendor_name}'\n",
    "            and complex_ranges.first_seen <= timestamp '{dateto}' + interval '1' day\n",
    "            and complex_ranges.last_seen >= timestamp '{datefrom}' \n",
    "            and key_name = 'tv2_hhid'\n",
    "            and yy='{yy}'\n",
    "            and mm='{mm}' \n",
    "            and dd='{dd}'\n",
    "      ),\n",
    "      client_eventlog as (\n",
    "         select \n",
    "         *\n",
    "         from {clientid}_{crosswalk_suffix}.eventlog\n",
    "         where \n",
    "            datadatetime between timestamp '{datefrom}' \n",
    "            and timestamp '{dateto}' + interval '7' day\n",
    "      ),\n",
    "      hh_impressed_30days as (\n",
    "         select\n",
    "            distinct crosswalk_link_id as mapped_tv2_hhid\n",
    "         from campaign_universe ex\n",
    "         join client_eventlog ev on ev.crosswalk_link_id = ex.mapped_tv2_hhid\n",
    "         where\n",
    "            event_class='impression'\n",
    "            and datadatetime between timestamp '{datefrom}' - interval '30' day    \n",
    "            and timestamp '{dateto}' + interval '1' day + interval '6' day\n",
    "            and in_scope\n",
    "      ),\n",
    "      hh_control as (\n",
    "         select\n",
    "            distinct cu.mapped_tv2_hhid\n",
    "         from campaign_universe cu\n",
    "         left join hh_impressed_30days hh on hh.mapped_tv2_hhid  = cu.mapped_tv2_hhid\n",
    "         where hh.mapped_tv2_hhid is null\n",
    "      ),\n",
    "      n_hh_control_visited_per_day as (\n",
    "         select\n",
    "            mapped_tv2_hhid, \n",
    "            date_trunc('day', datadatetime) as day\n",
    "         from client_eventlog\n",
    "         join hh_control on crosswalk_link_id = mapped_tv2_hhid\n",
    "         where\n",
    "            event_class ='response' and event= 'all response'\n",
    "            and datadatetime between timestamp '{datefrom}' \n",
    "            and timestamp '{dateto}' + interval '6' day + interval '1' day\n",
    "            and in_scope in (TRUE, null)\n",
    "      )\n",
    "      select\n",
    "         *\n",
    "      from {result}\n",
    "\n",
    "'''.format(\n",
    "      vendor_name='inscape', \n",
    "      yy=yy_value, mm=mm_value,dd=dd_value,\n",
    "      crosswalk_suffix='produsa',\n",
    "      dateto=dateto_value, \n",
    "      datefrom=datefrom_value,  \n",
    "      clientid=clientid_value,\n",
    "      result=subquery_name\n",
    "      )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWqAJT43Kanr"
   },
   "outputs": [],
   "source": [
    "df_control_visited_pday= query_athena(\n",
    "    request, \n",
    "    query_control_visited_perday(\n",
    "        subquery_name='n_hh_control_visited_per_day',\n",
    "        yy_value=yy_input, mm_value=mm_input,dd_value=dd_input,\n",
    "        dateto_value=dateto_input, \n",
    "        datefrom_value=datefrom_input,  \n",
    "        clientid_value=clientid_input,\n",
    "        ))\n",
    "\n",
    "df_control_visited_pday.day = pd.to_datetime(df_control_visited_pday.day)\n",
    "# df_control_visited_pday.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZRYUF-zKanr",
    "outputId": "57cf3703-94fa-4639-f103-fef4b4f9e3df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175337, 2)\n",
      "64506\n"
     ]
    }
   ],
   "source": [
    "#total rows extracted from source: 175,337  (all visits, no impressions cause we are in the control)\n",
    "print(df_control_visited_pday.shape)\n",
    "\n",
    "# number of unique hhs in control visited group = 64,506\n",
    "print(df_control_visited_pday.mapped_tv2_hhid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgYQW_Q7Kans"
   },
   "outputs": [],
   "source": [
    "df_control_visited_pday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vXQhiLAKans"
   },
   "outputs": [],
   "source": [
    "# aggregating visits by hhid and date\n",
    "df_control_visited_pday_agg = pd.DataFrame(\n",
    "    df_control_visited_pday.groupby(\n",
    "        ['mapped_tv2_hhid', 'day'], \n",
    "        as_index=True\n",
    "        ).mapped_tv2_hhid.count()\n",
    "    ).rename(columns={'mapped_tv2_hhid':'num_visits'}).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYD-KUSVKans"
   },
   "outputs": [],
   "source": [
    "# adding visited flag\n",
    "df_control_visited_pday=df_control_visited_pday_agg.assign(visited = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSCyT7y7Kans"
   },
   "outputs": [],
   "source": [
    "df_control_visited_pday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PTjxZDhKans",
    "outputId": "060742e0-34fb-40af-a46b-2684f1925082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175337\n",
      "64506\n"
     ]
    }
   ],
   "source": [
    "print(df_control_visited_pday.num_visits.sum()) #number of visits by control: 175,337 \n",
    "print(df_control_visited_pday.mapped_tv2_hhid.nunique()) # number of unique hhs in control visited group = 64,506"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DiZX03nKans"
   },
   "source": [
    "### ➡️ Exposed data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTlAMcFEKant"
   },
   "source": [
    "#### ➜ All exposed hhs per day and exposed visited per day\n",
    "\n",
    "Tables created:\n",
    "- df_exposed_visited_pday\n",
    "- df_exposed_visited_pday_agg\n",
    "- df_exposed_pday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYSm6AAeKant"
   },
   "outputs": [],
   "source": [
    "def query_exposed_visited_perday(subquery_name: str, yy_value:str, mm_value:str, dd_value:str, dateto_value:str, datefrom_value:str, clientid_value:str):\n",
    "   return '''\n",
    "   with filtered_hh as (\n",
    "   select \n",
    "        key_value as mapped_tv2_hhid\n",
    "   from {crosswalk_suffix}_modeldata.crosswalk\n",
    "   where \n",
    "        yy='{yy}' \n",
    "        and mm='{mm}' \n",
    "        and dd='{dd}'\n",
    "        and key_name ='tv2_hhid' \n",
    "        and vendor_name = '{vendor_name}'\n",
    "        and excluded_stamp is null\n",
    "   ),\n",
    "   campaign_universe as (\n",
    "      select \n",
    "         complex_ranges.mapped_tv2_hhid \n",
    "      FROM {crosswalk_suffix}_modeldata.crosswalk cw\n",
    "      CROSS JOIN UNNEST(complex_range) AS t (complex_ranges)\n",
    "      join filtered_hh fh on fh.mapped_tv2_hhid = complex_ranges.mapped_tv2_hhid\n",
    "      where \n",
    "         vendor_name = '{vendor_name}'\n",
    "         and complex_ranges.first_seen <= timestamp '{dateto}' + interval '1' day\n",
    "         and complex_ranges.last_seen >= timestamp '{datefrom}' \n",
    "         and key_name = 'tv2_hhid'\n",
    "         and yy='{yy}'\n",
    "         and mm='{mm}' \n",
    "         and dd='{dd}'\n",
    "   ),\n",
    "   client_eventlog as (\n",
    "      select \n",
    "      *\n",
    "      from {clientid}_{crosswalk_suffix}.eventlog\n",
    "      where \n",
    "         datadatetime between timestamp '{datefrom}' \n",
    "         and timestamp '{dateto}' + interval '7' day\n",
    "   ),\n",
    "   hh_impressed_in_campaign as (\n",
    "      select\n",
    "         distinct crosswalk_link_id as mapped_tv2_hhid\n",
    "      from campaign_universe ex\n",
    "      join client_eventlog ev on ev.crosswalk_link_id = ex.mapped_tv2_hhid\n",
    "      where\n",
    "         event_class='impression'\n",
    "         and event = 'linear'\n",
    "         and datadatetime between timestamp '{datefrom}' \n",
    "         and timestamp '{dateto}' + interval '1' day\n",
    "         and in_scope\n",
    "   ),\n",
    "   n_hh_impressed_visited_per_day as (\n",
    "      select \n",
    "         mapped_tv2_hhid,\n",
    "         date_trunc('day', datadatetime) as day,\n",
    "         case when (event_class ='response' and event= 'all response') then 1 else 0 end as visits\n",
    "      from client_eventlog\n",
    "      join hh_impressed_in_campaign on crosswalk_link_id = mapped_tv2_hhid\n",
    "      where\n",
    "         ((event_class ='response' and event= 'all response') or (event_class='impression' and event = 'linear'))\n",
    "         and datadatetime between timestamp '{datefrom}' \n",
    "         and timestamp '{dateto}' + interval '6' day + interval '1' day\n",
    "         and in_scope in (TRUE, null)\n",
    "   )\n",
    "   select\n",
    "      *\n",
    "   from {result}\n",
    "   \n",
    "'''.format(\n",
    "   vendor_name='inscape', \n",
    "   yy=yy_value, mm=mm_value,dd=dd_value,\n",
    "   crosswalk_suffix='produsa',\n",
    "   dateto=dateto_value, \n",
    "   datefrom=datefrom_value,  \n",
    "   clientid=clientid_value,\n",
    "   result=subquery_name\n",
    "   )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO4EiPuSKant",
    "outputId": "54ab44e6-308d-402a-eb5e-bfe1316988cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mapped_tv2_hhid            object\n",
       "day                datetime64[ns]\n",
       "visits                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exposed_visited_pday= query_athena(\n",
    "    request,\n",
    "    query_exposed_visited_perday(\n",
    "        subquery_name='n_hh_impressed_visited_per_day',\n",
    "        yy_value=yy_input, mm_value=mm_input,dd_value=dd_input,\n",
    "        dateto_value=dateto_input, \n",
    "        datefrom_value=datefrom_input,  \n",
    "        clientid_value=clientid_input,\n",
    "    )).astype({\"visits\": \"int\"})\n",
    "\n",
    "df_exposed_visited_pday.day = pd.to_datetime(df_exposed_visited_pday.day)\n",
    "df_exposed_visited_pday.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qE-tM6aKant",
    "outputId": "4ca69453-1cd0-4007-957d-46060ea410f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4961585, 3)\n",
      "40529\n",
      "16069\n",
      "1007152\n"
     ]
    }
   ],
   "source": [
    "#total rows extracted from source: 4,961,585 (all visits and impressions)\n",
    "print(df_exposed_visited_pday.shape)\n",
    "\n",
    "# number of total visits exposed group = 40,529 (extra information)\n",
    "print(df_exposed_visited_pday.visits.sum())\n",
    "\n",
    "# number of hhs that visited in exposed = 16,069\n",
    "print(df_exposed_visited_pday.loc[df_exposed_visited_pday['visits']>0,'mapped_tv2_hhid'].nunique())\n",
    "\n",
    "# number of hhs in exposed = 1,007,512\n",
    "print(df_exposed_visited_pday.mapped_tv2_hhid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7CVHRSKKant"
   },
   "outputs": [],
   "source": [
    "df_exposed_visited_pday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEUkXeUmKanu"
   },
   "outputs": [],
   "source": [
    "# aggregating table to count num of visits per hhid and day\n",
    "df_exposed_visited_pday_agg = pd.DataFrame(\n",
    "    df_exposed_visited_pday.groupby(\n",
    "        ['mapped_tv2_hhid', 'day'], \n",
    "        as_index=True\n",
    "        ).visits.sum()\n",
    "    ).rename(columns={'visits':'num_visits'}).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kN-fDPpNKanu"
   },
   "outputs": [],
   "source": [
    "df_exposed_visited_pday_agg[df_exposed_visited_pday_agg[\"num_visits\"]>1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Sg5npOjKanu",
    "outputId": "32ddc2f0-ad42-4ca0-aff9-89aa65b0c22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40529\n",
      "1007152\n",
      "(2580817, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_exposed_visited_pday_agg.num_visits.sum())\n",
    "print(df_exposed_visited_pday_agg.mapped_tv2_hhid.nunique())\n",
    "print(df_exposed_visited_pday_agg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q56TOO-wKanu"
   },
   "source": [
    "Creating visited flag for exposed df - final exposed table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHzzSzf0Kanu"
   },
   "outputs": [],
   "source": [
    "df_exposed_pday=df_exposed_visited_pday_agg.assign(visited = np.where(df_exposed_visited_pday_agg.num_visits>0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEr3Ph9SKanu"
   },
   "outputs": [],
   "source": [
    "df_exposed_pday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBm3VyqyKanv",
    "outputId": "a0ddbc9d-fab4-4679-802a-c3eb1fecb49a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2580817, 4)\n",
      "40529\n",
      "16069\n",
      "1007152\n"
     ]
    }
   ],
   "source": [
    "#total rows of exposed df: 2,580,817 (aggregated visits per hhid per day and hhids that were impressed)\n",
    "print(df_exposed_pday.shape)\n",
    "\n",
    "# number of total visits exposed group = 40,529 (extra information)\n",
    "print(df_exposed_pday.num_visits.sum())\n",
    "\n",
    "# number of hhs that visited in exposed = 16,069\n",
    "print(df_exposed_pday.loc[df_exposed_pday['num_visits']>0,'mapped_tv2_hhid'].nunique())\n",
    "\n",
    "# number of hhs in exposed group= 1,007,512\n",
    "print(df_exposed_pday.mapped_tv2_hhid.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhGt92sYKanv"
   },
   "source": [
    "## ✅️ Step2. Creating base data frame with ctrl group and visited flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHyUHejdKanv"
   },
   "source": [
    "### Creating flags and merging the 2 data sets (ctrl and exposed)\n",
    "- control group flag: This indicates if a hh belongs to the control group or not\n",
    "- visited flag: Indicates if a hh visited the clients website on the time frame specified. <br> \n",
    "From sql query: <br> \n",
    "    (event_class ='response' and event= 'all response' <br> \n",
    "       and datadatetime between timestamp '{datefrom}' and timestamp '{dateto}' + interval '6' day + interval '1' day <br> \n",
    "       and in_scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3MOp4cUKanv"
   },
   "source": [
    " #### ➜ Per day data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lilmD_4JKanv",
    "outputId": "20dc00c4-e323-4ac5-a0dd-fb95fac033f1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_control_visited_pday' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chiom/git/datascience/tv2ds/demographics/control groups/RAD-570 Control group functions - Daily level.ipynb Cell 49\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chiom/git/datascience/tv2ds/demographics/control%20groups/RAD-570%20Control%20group%20functions%20-%20Daily%20level.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_control_visited_pday\u001b[39m=\u001b[39mdf_control_visited_pday\u001b[39m.\u001b[39massign(ctrl_flag \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chiom/git/datascience/tv2ds/demographics/control%20groups/RAD-570%20Control%20group%20functions%20-%20Daily%20level.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_exposed_pday\u001b[39m=\u001b[39mdf_exposed_pday\u001b[39m.\u001b[39massign(ctrl_flag \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chiom/git/datascience/tv2ds/demographics/control%20groups/RAD-570%20Control%20group%20functions%20-%20Daily%20level.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m base_df_pday\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([df_control_visited_pday, df_exposed_pday], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_control_visited_pday' is not defined"
     ]
    }
   ],
   "source": [
    "df_control_visited_pday=df_control_visited_pday.assign(ctrl_flag = 1)\n",
    "df_exposed_pday=df_exposed_pday.assign(ctrl_flag = 0)\n",
    "base_df_pday=pd.concat([df_control_visited_pday, df_exposed_pday], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vBnQ-o_Kanv"
   },
   "outputs": [],
   "source": [
    "base_df_pday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWN4xmdhKanw",
    "outputId": "62de9918-e1c8-4ad1-c1e8-eb6ee27dc009"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2686892, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df_pday.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn98CFu8Kanw"
   },
   "source": [
    "## ✅️ Step3. Calculate metrics and choose variables to group data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNM8V-0pKanw"
   },
   "source": [
    "### Metrics\n",
    "\n",
    "Metrics include:\n",
    "- exp_visited\t\n",
    "- exp_hh\t\n",
    "- ctrl_visited\t\n",
    "- ctrl_hh\t\n",
    "- exp_vr=exp_visited/exp_hh\t\n",
    "- ctrl_vr=ctrl_visited/ctrl_hh \n",
    "- uplift=(exp_visited/exp_hh - ctrl_visited/ctrl_hh)/ (ctrl_visited/ctrl_hh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs4Wp85qKanw"
   },
   "source": [
    "### ➜ Metric and pivot table Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDCxoGIaKanw"
   },
   "outputs": [],
   "source": [
    "def ctrl_hh_column(df: pd.DataFrame):\n",
    "    return np.where(df.ctrl_flag==1,1,0)\n",
    "\n",
    "def ctrl_visited_column(df: pd.DataFrame):\n",
    "    return np.where((df.ctrl_flag==1) & (df.visited==1),1,0)\n",
    "\n",
    "def exp_hh_column(df: pd.DataFrame):\n",
    "    return np.where(df.ctrl_flag==0,1,0)\n",
    "\n",
    "def exp_visited_column(df: pd.DataFrame):\n",
    "    return np.where((df.ctrl_flag==0) & (df.visited==1),1,0)\n",
    "\n",
    "def add_vars_for_metrics(df: pd.DataFrame):\n",
    "    return df.assign(\n",
    "        ctrl_hh=ctrl_hh_column,\n",
    "        ctrl_visited=ctrl_visited_column,\n",
    "        exp_hh=exp_hh_column,\n",
    "        exp_visited=exp_visited_column,\n",
    "    )\n",
    "\n",
    "def add_vars_for_exposed_metrics(df: pd.DataFrame):\n",
    "    return df.assign(\n",
    "        exp_hh=exp_hh_column,\n",
    "        exp_visited=exp_visited_column,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXK8FiOSKanw"
   },
   "outputs": [],
   "source": [
    "def pivot_table(df: pd.DataFrame, source_column_name: str, margins_value: str):\n",
    "    table = pd.pivot_table(\n",
    "        df,\n",
    "        values=['ctrl_hh', 'ctrl_visited','exp_hh','exp_visited'], \n",
    "        index=[source_column_name],\n",
    "        aggfunc=np.sum,\n",
    "        margins=margins_value)\n",
    "\n",
    "    table['ctrl_vr']=table.ctrl_visited/table.ctrl_hh\n",
    "    table['exp_vr']=table.exp_visited/table.exp_hh\n",
    "    table['uplift']=(table.exp_visited/table.exp_hh - table.ctrl_visited/table.ctrl_hh)/ (table.ctrl_visited/table.ctrl_hh)\n",
    "    table['diff_vr']=table.exp_vr - table.ctrl_vr \n",
    "\n",
    "\n",
    "    return table\n",
    "\n",
    "# Way to fix decimal places - need to reset the decimals options for the cell as the global ones are set at the start of the notebook\n",
    "# decimals = pd.Series([0, 0, 0, 0, 4], index=['ctrl_hh', 'ctrl_visited', 'exp_hh', 'exp_visited', 'ctrl_vr']) \n",
    "# table.round(decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcvurNv8Kanw"
   },
   "outputs": [],
   "source": [
    "def pivot_table_exposed_vars(df: pd.DataFrame, source_column_name: str, margins_value: str):\n",
    "    table = pd.pivot_table(\n",
    "        df,\n",
    "        values=['exp_hh','exp_visited'], \n",
    "        index=[source_column_name],\n",
    "        aggfunc=np.sum,\n",
    "        margins=margins_value)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejlDZsQEKanx"
   },
   "source": [
    "### ➜ High level metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FU6L2cGBKanx",
    "outputId": "99ee117b-3087-4b3a-914d-6691778b197d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_hh</th>\n",
       "      <th>exp_visited</th>\n",
       "      <th>exp_vr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2580817.000000</td>\n",
       "      <td>26446.000000</td>\n",
       "      <td>0.010247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            exp_hh  exp_visited   exp_vr\n",
       "All 2580817.000000 26446.000000 0.010247"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_metrics_table = pd.DataFrame(\n",
    "    base_df_pday\n",
    "    .pipe(add_vars_for_metrics)\n",
    "    .pipe(pivot_table, source_column_name='day', margins_value=True)\n",
    "    .loc['All']\n",
    "    ).T\n",
    "overall_metrics_table[['exp_hh','exp_visited','exp_vr']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k_o_lZqKanx"
   },
   "source": [
    "### ➜ Daily metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBc0AVK0Kanx"
   },
   "outputs": [],
   "source": [
    "base_df_pday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AL-GsVhVKanx"
   },
   "outputs": [],
   "source": [
    "df_exposed_pday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLIAktcoKanx",
    "outputId": "cc6b93a5-368b-4512-a192-2f499f52a46b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_hh</th>\n",
       "      <th>exp_visited</th>\n",
       "      <th>ctrl_hh</th>\n",
       "      <th>ctrl_visited</th>\n",
       "      <th>ctrl_vr</th>\n",
       "      <th>exp_vr</th>\n",
       "      <th>uplift</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>63260</td>\n",
       "      <td>672</td>\n",
       "      <td>8637847</td>\n",
       "      <td>17999</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>4.097969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-02</th>\n",
       "      <td>58923</td>\n",
       "      <td>676</td>\n",
       "      <td>8651376</td>\n",
       "      <td>18100</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>4.483634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03</th>\n",
       "      <td>49547</td>\n",
       "      <td>739</td>\n",
       "      <td>8651396</td>\n",
       "      <td>18248</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>6.071279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-04</th>\n",
       "      <td>55573</td>\n",
       "      <td>779</td>\n",
       "      <td>8629766</td>\n",
       "      <td>18041</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.014018</td>\n",
       "      <td>5.705205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-05</th>\n",
       "      <td>46612</td>\n",
       "      <td>874</td>\n",
       "      <td>8593316</td>\n",
       "      <td>17899</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.018751</td>\n",
       "      <td>8.002139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-06</th>\n",
       "      <td>40496</td>\n",
       "      <td>731</td>\n",
       "      <td>8571266</td>\n",
       "      <td>17811</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.018051</td>\n",
       "      <td>7.686842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>29937</td>\n",
       "      <td>455</td>\n",
       "      <td>8527104</td>\n",
       "      <td>17584</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.015199</td>\n",
       "      <td>6.370331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>44473</td>\n",
       "      <td>681</td>\n",
       "      <td>8511329</td>\n",
       "      <td>17837</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.015313</td>\n",
       "      <td>6.306784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>70183</td>\n",
       "      <td>697</td>\n",
       "      <td>8499405</td>\n",
       "      <td>17760</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>3.752766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-10</th>\n",
       "      <td>78049</td>\n",
       "      <td>676</td>\n",
       "      <td>8481764</td>\n",
       "      <td>17886</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>3.107261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-11</th>\n",
       "      <td>115575</td>\n",
       "      <td>751</td>\n",
       "      <td>8487444</td>\n",
       "      <td>18407</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>1.996194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-12</th>\n",
       "      <td>84236</td>\n",
       "      <td>799</td>\n",
       "      <td>8501427</td>\n",
       "      <td>18591</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>3.337486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-13</th>\n",
       "      <td>85173</td>\n",
       "      <td>663</td>\n",
       "      <td>8520186</td>\n",
       "      <td>18621</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>2.561703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>49626</td>\n",
       "      <td>551</td>\n",
       "      <td>8526963</td>\n",
       "      <td>18754</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>4.048273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "      <td>79332</td>\n",
       "      <td>606</td>\n",
       "      <td>8523827</td>\n",
       "      <td>18688</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>2.484143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-16</th>\n",
       "      <td>115389</td>\n",
       "      <td>773</td>\n",
       "      <td>8528520</td>\n",
       "      <td>18554</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>2.079294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-17</th>\n",
       "      <td>77571</td>\n",
       "      <td>882</td>\n",
       "      <td>8529257</td>\n",
       "      <td>18304</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>4.298274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-18</th>\n",
       "      <td>90687</td>\n",
       "      <td>939</td>\n",
       "      <td>8501520</td>\n",
       "      <td>17897</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>3.918548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-19</th>\n",
       "      <td>60729</td>\n",
       "      <td>932</td>\n",
       "      <td>8489143</td>\n",
       "      <td>17809</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.015347</td>\n",
       "      <td>6.315501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-20</th>\n",
       "      <td>68896</td>\n",
       "      <td>744</td>\n",
       "      <td>8473311</td>\n",
       "      <td>17451</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.010799</td>\n",
       "      <td>4.243385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-21</th>\n",
       "      <td>77271</td>\n",
       "      <td>553</td>\n",
       "      <td>8454286</td>\n",
       "      <td>17293</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>2.498768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-22</th>\n",
       "      <td>78957</td>\n",
       "      <td>519</td>\n",
       "      <td>8314182</td>\n",
       "      <td>17396</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>2.141571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-23</th>\n",
       "      <td>122438</td>\n",
       "      <td>615</td>\n",
       "      <td>8316898</td>\n",
       "      <td>17551</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>1.380227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-24</th>\n",
       "      <td>137063</td>\n",
       "      <td>726</td>\n",
       "      <td>8340302</td>\n",
       "      <td>18031</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>1.450069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-25</th>\n",
       "      <td>127559</td>\n",
       "      <td>815</td>\n",
       "      <td>8372457</td>\n",
       "      <td>18525</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>1.887628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-26</th>\n",
       "      <td>94873</td>\n",
       "      <td>891</td>\n",
       "      <td>8404119</td>\n",
       "      <td>18314</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>3.309670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-27</th>\n",
       "      <td>87980</td>\n",
       "      <td>702</td>\n",
       "      <td>8422147</td>\n",
       "      <td>18053</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>2.722430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-28</th>\n",
       "      <td>45215</td>\n",
       "      <td>582</td>\n",
       "      <td>8376975</td>\n",
       "      <td>17980</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>4.997054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29</th>\n",
       "      <td>87758</td>\n",
       "      <td>649</td>\n",
       "      <td>8391511</td>\n",
       "      <td>18167</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>2.415977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-30</th>\n",
       "      <td>95354</td>\n",
       "      <td>841</td>\n",
       "      <td>8439166</td>\n",
       "      <td>18063</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>3.120659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>89276</td>\n",
       "      <td>820</td>\n",
       "      <td>8499831</td>\n",
       "      <td>17962</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>3.346450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            exp_hh  exp_visited  ctrl_hh  ctrl_visited  ctrl_vr   exp_vr  \\\n",
       "day                                                                        \n",
       "2022-03-01   63260          672  8637847         17999 0.002084 0.010623   \n",
       "2022-03-02   58923          676  8651376         18100 0.002092 0.011473   \n",
       "2022-03-03   49547          739  8651396         18248 0.002109 0.014915   \n",
       "2022-03-04   55573          779  8629766         18041 0.002091 0.014018   \n",
       "2022-03-05   46612          874  8593316         17899 0.002083 0.018751   \n",
       "2022-03-06   40496          731  8571266         17811 0.002078 0.018051   \n",
       "2022-03-07   29937          455  8527104         17584 0.002062 0.015199   \n",
       "2022-03-08   44473          681  8511329         17837 0.002096 0.015313   \n",
       "2022-03-09   70183          697  8499405         17760 0.002090 0.009931   \n",
       "2022-03-10   78049          676  8481764         17886 0.002109 0.008661   \n",
       "2022-03-11  115575          751  8487444         18407 0.002169 0.006498   \n",
       "2022-03-12   84236          799  8501427         18591 0.002187 0.009485   \n",
       "2022-03-13   85173          663  8520186         18621 0.002186 0.007784   \n",
       "2022-03-14   49626          551  8526963         18754 0.002199 0.011103   \n",
       "2022-03-15   79332          606  8523827         18688 0.002192 0.007639   \n",
       "2022-03-16  115389          773  8528520         18554 0.002176 0.006699   \n",
       "2022-03-17   77571          882  8529257         18304 0.002146 0.011370   \n",
       "2022-03-18   90687          939  8501520         17897 0.002105 0.010354   \n",
       "2022-03-19   60729          932  8489143         17809 0.002098 0.015347   \n",
       "2022-03-20   68896          744  8473311         17451 0.002060 0.010799   \n",
       "2022-03-21   77271          553  8454286         17293 0.002045 0.007157   \n",
       "2022-03-22   78957          519  8314182         17396 0.002092 0.006573   \n",
       "2022-03-23  122438          615  8316898         17551 0.002110 0.005023   \n",
       "2022-03-24  137063          726  8340302         18031 0.002162 0.005297   \n",
       "2022-03-25  127559          815  8372457         18525 0.002213 0.006389   \n",
       "2022-03-26   94873          891  8404119         18314 0.002179 0.009392   \n",
       "2022-03-27   87980          702  8422147         18053 0.002144 0.007979   \n",
       "2022-03-28   45215          582  8376975         17980 0.002146 0.012872   \n",
       "2022-03-29   87758          649  8391511         18167 0.002165 0.007395   \n",
       "2022-03-30   95354          841  8439166         18063 0.002140 0.008820   \n",
       "2022-03-31   89276          820  8499831         17962 0.002113 0.009185   \n",
       "\n",
       "             uplift  \n",
       "day                  \n",
       "2022-03-01 4.097969  \n",
       "2022-03-02 4.483634  \n",
       "2022-03-03 6.071279  \n",
       "2022-03-04 5.705205  \n",
       "2022-03-05 8.002139  \n",
       "2022-03-06 7.686842  \n",
       "2022-03-07 6.370331  \n",
       "2022-03-08 6.306784  \n",
       "2022-03-09 3.752766  \n",
       "2022-03-10 3.107261  \n",
       "2022-03-11 1.996194  \n",
       "2022-03-12 3.337486  \n",
       "2022-03-13 2.561703  \n",
       "2022-03-14 4.048273  \n",
       "2022-03-15 2.484143  \n",
       "2022-03-16 2.079294  \n",
       "2022-03-17 4.298274  \n",
       "2022-03-18 3.918548  \n",
       "2022-03-19 6.315501  \n",
       "2022-03-20 4.243385  \n",
       "2022-03-21 2.498768  \n",
       "2022-03-22 2.141571  \n",
       "2022-03-23 1.380227  \n",
       "2022-03-24 1.450069  \n",
       "2022-03-25 1.887628  \n",
       "2022-03-26 3.309670  \n",
       "2022-03-27 2.722430  \n",
       "2022-03-28 4.997054  \n",
       "2022-03-29 2.415977  \n",
       "2022-03-30 3.120659  \n",
       "2022-03-31 3.346450  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_pday = pd.DataFrame(\n",
    "    base_df_pday\n",
    "    .pipe(add_vars_for_exposed_metrics)\n",
    "    .pipe(pivot_table_exposed_vars, source_column_name='day', margins_value=False)\n",
    "    .merge(df_control_daily.set_index('day'), right_index=True, left_index=True)\n",
    "    .assign(\n",
    "        exp_vr=lambda df: df.exp_visited/df.exp_hh,\n",
    "        ctrl_vr=lambda df: df.ctrl_visited/df.ctrl_hh,\n",
    "        uplift=lambda df: (df.exp_visited/df.exp_hh - df.ctrl_visited/df.ctrl_hh)/ (df.ctrl_visited/df.ctrl_hh),\n",
    "    ))\n",
    "\n",
    "metrics_df_pday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYnyjq-GKanx"
   },
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "# metrics_df_pday.to_csv('daily_drizly_Mar2022.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUJfCk8cKanx"
   },
   "source": [
    "## ✅️ Step4. Grouping Sample sizes analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jid2j5W9Kany"
   },
   "outputs": [],
   "source": [
    "#Random sampling\n",
    "\n",
    "def random_sampling(df, percentage_from_df,random_state_value):\n",
    "    random_sample = df.sample(frac=percentage_from_df, replace=False, random_state=random_state_value)\n",
    "    return(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEt1H9iKKany"
   },
   "outputs": [],
   "source": [
    "# For reproducibility - random_state=1\n",
    "randomSample = random_sampling(base_df_pday, 0.20, random_state_value=1)\n",
    "randomSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "168LE10bKany"
   },
   "outputs": [],
   "source": [
    "# at the moment this function creates the whole pivot table first but \n",
    "# there is probably a more efficent way of calculaing the metrics of the overall sample without creating a pivot table \n",
    "dfs=[]\n",
    "for i in range(100):\n",
    "    sampled_df=pd.DataFrame(\n",
    "        random_sampling(base_df_pday, 0.20, random_state_value=None)\n",
    "        .pipe(add_vars_for_metrics)\n",
    "        .pipe(pivot_table, source_column_name='hh_detail_life', margins_value=True)\n",
    "        .loc['All']\n",
    "        ).T\n",
    "    dfs.append(sampled_df)\n",
    "final_sampled_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRIfCdD0Kany",
    "outputId": "512789b2-5ee2-4192-dc69-fb88ebeb5d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2613 would be the smallest value of sample size that would be significant for a desired detecting effect of at least + 0.5% in visiting rate in exposed sample\n",
      "0.42705572914969225% would be the minium Visiting Rate value that would be significant for given value of N = 110000 in exposed sample\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "\n",
    "## What is  the N (sample size) given %\n",
    "\n",
    "\n",
    "alpha = 0.05                    # Type 1 error: Percent of the time a difference will be detected, when in fact there are none\n",
    "beta  = 0.2                     # Type 2 error: percent of the time the minimum effect size will NOT be detected, assuming it exists\n",
    "Qalpha = scipy.stats.norm.ppf(1-alpha/2)      # quantile value\n",
    "Qbeta  = scipy.stats.norm.ppf(beta)           # quantile value\n",
    "Pc   = 0.0035                   # Base Visiting Rate for Control\n",
    "Dmin = 0.005                    # Min value of the diference between vr control and the vr exposed (practical significance, detecting % that makes business sense from client perspective)\n",
    "Pt   = Pc + Dmin             # Visiting Rate (base + min detected) for Treatment (Null hypothesis for Beta)\n",
    "\n",
    "sd1 = math.sqrt(2*Pc*(1-Pc))\n",
    "sd2 = math.sqrt((Pc)*(1-Pc) + Pt*(1-Pt))\n",
    "N   = math.ceil(((Qalpha*sd1 - Qbeta*sd2)/(Dmin))**2)\n",
    "N # min value in exposed (includes both visited and not)\n",
    "\n",
    "print(f\"{N} would be the smallest value of exposed sample size that would be significant for a desired detecting effect of at least + {Dmin*100}% in visiting rate in exposed sample\")\n",
    "## ----------------------------------------- ----------------------------------------- ----------------------------------------- -----------------------------------------##\n",
    "\n",
    "## where N is set, what % is significant\n",
    "\n",
    "\n",
    "alpha = 0.05                    # Type 1 error: Percent of the time a difference will be detected, when in fact there are none\n",
    "beta  = 0.2                     # Type 2 error: percent of the time the minimum effect size will NOT be detected, assuming it exists\n",
    "Qalpha = scipy.stats.norm.ppf(1-alpha/2)      # quantile value\n",
    "Qbeta  = scipy.stats.norm.ppf(beta)           # quantile value\n",
    "Pc   = 0.0035                   # Base Visiting Rate for Control\n",
    "sd1 = math.sqrt(2*Pc*(1-Pc))\n",
    "sd2 = math.sqrt((Pc)*(1-Pc) + Pt*(1-Pt))\n",
    "N = 110000 #exposed people\n",
    "\n",
    "Dmin = (Qalpha*sd1 - Qbeta*sd2)/math.sqrt(N)\n",
    "\n",
    "print(f\"{(Pc + Dmin)*100}% would be the minium Visiting Rate value that would be significant for given value of N = {N} in exposed sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMQC56eAKany",
    "outputId": "881648b4-00be-455e-c161-0b13e0f6509c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.959963984540054\n",
      "-0.8416212335729142\n"
     ]
    }
   ],
   "source": [
    "print(Qalpha)\n",
    "print(Qbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdrO_y60Kany",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_control_group_sampled(\n",
    "    request, datefrom_value:str, dateto_value:str, yy_value:str, mm_value:str, dd_value:str,clientid_value:str, \n",
    "    granularity:str, lookback_window:int, filter_linear=True,):\n",
    "    \"\"\"\n",
    "    Slow version to get us off the ground. Take a date range and then it will run the athena query per granularity\n",
    "    specified to get the aggregate totals for eligible control households and the number of visits\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    request : Request\n",
    "        request object\n",
    "    datefrom : str\n",
    "        start date for date range\n",
    "    dateto : str\n",
    "        end date for date range\n",
    "    cw_yy : int\n",
    "        crosswalk year\n",
    "    cw_mm : int\n",
    "        crosswalk month\n",
    "    cw_dd : int\n",
    "        crosswalk day\n",
    "    granularity: what frequency to pass to pandas for date range, W (weekly) or D (daily) -- (hint: weekly on Monday is 'W-MON' ?)\n",
    "    lookback_window : int\n",
    "        how far to look back to fund elibigle households, e.g. not exposed in last '30' days\n",
    "    crosswalk_suffix : str\n",
    "        which env are you using, default 'prod'\n",
    "    vendor_name : str\n",
    "        crosswalk vendor name e.g. inscape\n",
    "    filter_linear : bool\n",
    "        should we consider both OTT and Linear impressions when building the control group? default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        control households and visits per granularity specified, with visit rate calculated\n",
    "\n",
    "    Version control\n",
    "    -------\n",
    "    Created by: Michael Comerford\n",
    "    Last Modified by: Chio Martinez 10th Oct \n",
    "        - introduced change on concatenated df to use concat instead of append in the final df\n",
    "        - introduced granularity functionality: 'W' and 'D'\n",
    "        - changes to function call and parameters \n",
    "\n",
    "    \"\"\"\n",
    "    # get db from request object\n",
    "    athena_db = AthenaDatabase.get_client_database(request)\n",
    "\n",
    "    # create list of dates from specified range\n",
    "    datelist = pd.date_range(start=datefrom_input, end=dateto_input, freq=granularity).to_list()\n",
    "\n",
    "    # if filter_linear is true we need to remove the event filter\n",
    "    overlap = ''\n",
    "    if not filter_linear:\n",
    "        overlap = \"and event = 'vod'\"\n",
    "\n",
    "    # we'll store the aggregated results in a DataFrame\n",
    "    dfs=[]\n",
    "\n",
    "\n",
    "    for date in datelist:\n",
    "\n",
    "        # if granularity = 'W' then date datefrom=date - 7 days, \n",
    "        datefrom_granularity = date\n",
    "        if granularity == 'W':\n",
    "            datefrom_granularity = date - timedelta(days=6)\n",
    "\n",
    "        print(\n",
    "            '''Getting Data for dates between {datefrom} until {dateto}...'''\n",
    "            .format(\n",
    "                dateto=date, \n",
    "                datefrom=datefrom_granularity)\n",
    "            )\n",
    "\n",
    "        query = \"\"\"\n",
    "        -- select universe of unfiltered people for time range\n",
    "        \n",
    "\n",
    "        with filtered_hh as (\n",
    "        select \n",
    "            key_value as mapped_tv2_hhid\n",
    "        from {crosswalk_suffix}_modeldata.crosswalk \n",
    "        where \n",
    "            yy='{yy}' \n",
    "            and mm='{mm}' \n",
    "            and dd='{dd}'\n",
    "            and key_name ='tv2_hhid' \n",
    "            and vendor_name = '{vendor_name}'\n",
    "            and excluded_stamp is null\n",
    "        ),\n",
    "        campaign_universe as (\n",
    "            select \n",
    "                complex_ranges.mapped_tv2_hhid \n",
    "            FROM {crosswalk_suffix}_modeldata.crosswalk cw \n",
    "            CROSS JOIN UNNEST(complex_range) AS t (complex_ranges)\n",
    "            join filtered_hh fh on fh.mapped_tv2_hhid = complex_ranges.mapped_tv2_hhid\n",
    "            where \n",
    "                vendor_name = '{vendor_name}'\n",
    "                and complex_ranges.first_seen <= timestamp '{dateto}' + interval '1' day\n",
    "                and complex_ranges.last_seen >= timestamp '{datefrom}' \n",
    "                and key_name = 'tv2_hhid'\n",
    "                and yy='{yy}'\n",
    "                and mm='{mm}' \n",
    "                and dd='{dd}'\n",
    "        ),\n",
    "        client_eventlog as (\n",
    "            select \n",
    "            *\n",
    "            from {clientid}_{crosswalk_suffix}.eventlog\n",
    "            where \n",
    "                datadatetime between timestamp '{datefrom}' \n",
    "                and timestamp '{dateto}' + interval '7' day\n",
    "        ),\n",
    "        hh_impressed_30days as (\n",
    "            select\n",
    "                distinct crosswalk_link_id as mapped_tv2_hhid\n",
    "            from campaign_universe ex\n",
    "            join client_eventlog ev on ev.crosswalk_link_id = ex.mapped_tv2_hhid\n",
    "            where\n",
    "                event_class='impression'\n",
    "                {overlap}\n",
    "                and datadatetime between timestamp '{datefrom}' - interval '{lookback_window}' day    \n",
    "                and timestamp '{dateto}' + interval '7' day\n",
    "                and in_scope\n",
    "        ),\n",
    "        hh_control as (\n",
    "            select\n",
    "                distinct cu.mapped_tv2_hhid\n",
    "            from campaign_universe cu\n",
    "            left join hh_impressed_30days hh on hh.mapped_tv2_hhid  = cu.mapped_tv2_hhid\n",
    "            where hh.mapped_tv2_hhid is null\n",
    "        ),\n",
    "        n_hh_control_visited as (\n",
    "            select \n",
    "                count(distinct mapped_tv2_hhid) as ctrl_visited\n",
    "            from client_eventlog\n",
    "            join hh_control on crosswalk_link_id = mapped_tv2_hhid \n",
    "            where\n",
    "                event_class ='response' and event= 'all response'\n",
    "                and datadatetime between timestamp '{datefrom}' \n",
    "                and timestamp '{dateto}' + interval '7' day\n",
    "                and in_scope in (TRUE, null)\n",
    "        ),\n",
    "        n_hh_control as (\n",
    "            select CAST(count(distinct mapped_tv2_hhid) AS double) as ctrl_hh\n",
    "            from hh_control\n",
    "        ),\n",
    "        final_results as (\n",
    "            select *\n",
    "            from n_hh_control_visited\n",
    "            cross join n_hh_control\n",
    "        )\n",
    "        select\n",
    "            '{datefrom}' as day, \n",
    "            ctrl_hh,\n",
    "            ctrl_visited,\n",
    "            ctrl_visited/ctrl_hh as ctrl_vr\n",
    "        from final_results\n",
    "\n",
    "        \"\"\".format(\n",
    "            yy=yy_value, mm=mm_value, dd=dd_value,\n",
    "            dateto=date, \n",
    "            datefrom=datefrom_granularity,  \n",
    "            clientid=clientid_value,\n",
    "            lookback_window=lookback_window, \n",
    "            overlap=overlap,\n",
    "            vendor_name='inscape',\n",
    "            crosswalk_suffix='produsa',\n",
    "            )   \n",
    "\n",
    "        query_results = AthenaDatabase.execute_query(athena_db, query)\n",
    "        \n",
    "        dfs.append(pd.DataFrame(query_results))\n",
    "        results = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "        request.log.info(query)\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWkXX53UKanz",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "yy_input='2022' \n",
    "mm_input='03'\n",
    "dd_input='28'\n",
    "dateto_input='2022-04-03' \n",
    "datefrom_input='2022-03-01'  \n",
    "lookback_window_input=30\n",
    "clientid_input='c9306_drizly'\n",
    "# clientid_input='c9534_uti'\n",
    "# clientid_input='c16319_the_realreal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ALjHeYHTKanz",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "11726dab-4ca9-4d37-a07e-96ba8b0269e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data for dates between 2022-02-28 00:00:00 until 2022-03-06 00:00:00...\n",
      "Getting Data for dates between 2022-03-07 00:00:00 until 2022-03-13 00:00:00...\n",
      "Getting Data for dates between 2022-03-14 00:00:00 until 2022-03-20 00:00:00...\n",
      "Getting Data for dates between 2022-03-21 00:00:00 until 2022-03-27 00:00:00...\n",
      "Getting Data for dates between 2022-03-28 00:00:00 until 2022-04-03 00:00:00...\n"
     ]
    }
   ],
   "source": [
    "granularity_input='W'\n",
    "\n",
    "df_control_weekly= get_control_group(\n",
    "    request=request_ctrl_fun, \n",
    "    yy_value=yy_input, mm_value=mm_input,dd_value=dd_input,\n",
    "    granularity=granularity_input,\n",
    "    lookback_window=lookback_window_input,\n",
    "    dateto_value=dateto_input, \n",
    "    datefrom_value=datefrom_input,  \n",
    "    clientid_value=clientid_input,\n",
    "    )\n",
    "\n",
    "df_control_weekly.day = pd.to_datetime(df_control_weekly.day).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "KsU4Uo7RKanz",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "3e8ca85a-b1ca-4f3a-9b28-0da7443b0bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2022-03-06 00:00:00', freq='W-SUN'),\n",
       " Timestamp('2022-03-13 00:00:00', freq='W-SUN'),\n",
       " Timestamp('2022-03-20 00:00:00', freq='W-SUN'),\n",
       " Timestamp('2022-03-27 00:00:00', freq='W-SUN'),\n",
       " Timestamp('2022-04-03 00:00:00', freq='W-SUN')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datelist = pd.date_range(start=datefrom_input, end=dateto_input, freq=\"W\").to_list()\n",
    "datelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSQmg6DJKanz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "774219920b656a50e8f8bdbdeb9dc75bd2e22b7e0c90a46528a3ef3f55aa16a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
